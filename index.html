
<html>
  	<head>
	    <title>Dongdong Chen</title>
	    <script src='http://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js'></script>
	    <link href='css/bootstrap.min.css' rel='stylesheet'>
	    <link href='css/homepage_style.css' rel='stylesheet'>
	    <script src='js/bootstrap.min.js'></script>
		<script>
		  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

		  ga('create', 'UA-96260956-1', 'auto');
		  ga('send', 'pageview');

		</script>
      <link href='http://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900,100italic,100,300,300italic,400italic,500italic,900italic,700italic' rel='stylesheet' type='text/css'>
	</head>
	<body>
		<div id='header' class ='bg'>
	      	<div id='header-inner'>
		        <img src='images/donnie_chen.png' class='img-me'>
		        <div class='header-text'>
		          <div class='header-text-name'>
		            Dongdong Chen
		          </div>
		          <div class='header-text-email'>
		            cddlyf at gmail dot com
		          </div>
		        </div>
	    	</div>
    	</div>
    	<div class='container'>
      		<div class='col-xs-12'>

        	<div class='row about'>
			<p>I am currently a principal research manager at Microsoft GenAI and leading the large-scale multi-modality foundation model development. Before that, I obtained my PhD degree in <a href="http://en.ustc.edu.cn/", target="_blank">University of Science and Technology of China (USTC)</a> under the joint PhD program between MSRA and USTC in 2019. I was luckily advised by <a href="http://www.ganghua.org/", target="_blank">Gang Hua</a>, <A href="https://www.microsoft.com/en-us/research/people/luyuan/", target="_blank">Lu Yuan</A>, <A href="https://www.microsoft.com/en-us/research/people/jliao/", target="_blank">Jing Liao</A> and <A href="http://staff.ustc.edu.cn/~ynh/", target="_blank">Prof. Nenghai Yu</A>. My research interests are in computer vision and deep learning. I'm particularly interested in the areas of image generation, style transfer, object detection and AI security. You can find my cv <a target="_blank" href="cv.pdf">here</a>.</p> 
        </div>

        <div class='row'>
          <hr>
        </div>

         <div class='row'>
          <h1>Publications</h1>
        </div>
		<div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/uni-controlnet.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'> 
            Uni-ControlNet: All-in-One Control to Text-to-Image Diffusion Models
            </div>
            <div class='paper-authors'>
            Shihao Zhao, <b>Dongdong Chen</b>, Yen-Chun Chen, Jianmin Bao, Shaozhe Hao, Lu Yuan, Kwan-Yee K. Wong
            </div>
            <div class='paper-venue'>
              Thirty-Seventh Conference on Neural Information Processing Systems (NeurIPs 2023)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/abs/2305.16322">[pdf]</a>
              <a target="_blank" href="https://github.com/ShihaoZhaoZSH/Uni-ControlNet">[code]</a>
              
            </div>
          </div>
        </div>
		<div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/richsem.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'> 
            Learning from Rich Semantics and Coarse Locations for Long-tailed Object Detection
            </div>
            <div class='paper-authors'>
            Lingchen Meng, Xiyang Dai, Jianwei Yang, <b>Dongdong Chen</b>, Yinpeng Chen, Mengchen Liu, Yi-Ling Chen, Zuxuan Wu, Lu Yuan, Yu-Gang Jiang
            </div>
            <div class='paper-venue'>
              Thirty-Seventh Conference on Neural Information Processing Systems (NeurIPs 2023)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/abs/2310.12152">[pdf]</a>
              <a target="_blank" href="https://github.com/MengLcool/RichSem">[code]</a>
              
            </div>
          </div>
        </div>
        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/hairclipv2.png">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'> 
            HairCLIPv2: Unifying Hair Editing via Proxy Feature Blending
            </div>
            <div class='paper-authors'>
            Tianyi Wei, <b>Dongdong Chen</b>, Wenbo Zhou, Jing Liao, Weiming Zhang, Gang Hua,Nenghai Yu
            </div>
            <div class='paper-venue'>
              International Conference on Computer Vision (ICCV 2023)
            </div>
            <div>
              <a target="_blank" href="">[pdf(coming soon)]</a>
              <a target="_blank" href="">[code]</a>
              
            </div>
          </div>
        </div>
        

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/mae_adversarial.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'> 
            Improving Adversarial Robustness of Masked Autoencoders via Test-time Frequency-domain Prompting
            </div>
            <div class='paper-authors'>
            Qidong Huang, Xiaoyi Dong, <b>Dongdong Chen</b>, Yinpeng Chen, Lu Yuan, Gang Hua, Weiming Zhang, Nenghai Yu
            </div>
            <div class='paper-venue'>
              International Conference on Computer Vision (ICCV 2023)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/pdf/2308.10315v2.pdf">[pdf]</a>
              <a target="_blank" href="https://github.com/shikiw/RobustMAE">[code]</a>
              
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/avatar_craft.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'> 
            AvatarCraft: Transforming Text into Neural Human Avatars with Parameterized Shape and Pose Control
            </div>
            <div class='paper-authors'>
            Ruixiang Jiang, Can Wang, Jingbo Zhang, Menglei Chai, Mingming He, <b>Dongdong Chen</b>, Jing Liao
            </div>
            <div class='paper-venue'>
              International Conference on Computer Vision (ICCV 2023)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/abs/2303.17606">[pdf]</a>
              <a target="_blank" href="https://github.com/songrise/avatarcraft">[code]</a>
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/xpaste.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'> 
            X-Paste: Revisiting Scalable Copy-Paste for Instance Segmentation using CLIP and StableDiffusion
            </div>
            <div class='paper-authors'>
            Hanqing Zhao, Dianmo Sheng, Jianmin Bao, <b>Dongdong Chen</b>, et al., Nenghai Yu
            </div>
            <div class='paper-venue'>
              International Conference on Machine Learning (ICML 2023)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/pdf/2212.03863.pdf">[pdf]</a>
              <a target="_blank" href="https://github.com/yoctta/XPaste">[code]</a>
              
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/mvd.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'> 
            Masked Video Distillation: Rethinking Masked Feature Modeling for Self-supervised Video Representation Learning
            </div>
            <div class='paper-authors'>
            Rui Wang, <b>Dongdong Chen</b>, Zuxuan Wu, Yinpeng Chen, Xiyang Dai, Mengchen Liu, Lu Yuan, Yu-Gang Jiang
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2023)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/abs/2212.04500">[pdf]</a>
              <a target="_blank" href="https://github.com/ruiwang2021/mvd">[code]</a>
            </div>
          </div>
        </div>
        
        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/ISVOS.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
             Look Before You Match: Instance Understanding Matters in Video Object Segmentation
            </div>
            <div class='paper-authors'>
              Junke Wang, <b>Dongdong Chen</b>, Zuxuan Wu, Chong Luo, Chuanxin Tang, Xiyang Dai, Yucheng Zhao, Yujia Xie, Lu Yuan, Yu-Gang Jiang
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2023)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/abs/2212.06826">[pdf]</a>
              <a target="_blank" href="">[code]</a>
            </div>
          </div>
        </div>
        
        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/svm.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'> 
            Streaming Video Model 
            </div>
            <div class='paper-authors'>
            Yucheng Zhao, Chong Luo, Chuanxin Tang, <b>Dongdong Chen</b>, Noel C Codella, Zheng-Jun Zha
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2023)
            </div>
            <div>
              <a target="_blank" href="">[pdf]</a>
              <a target="_blank" href="">[code]</a>
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/dance.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'> 
            Improving Commonsense in Vision-Language Models via Knowledge Graph Riddles
            </div>
            <div class='paper-authors'>
            Shuquan Ye, Yujia Xie, <b>Dongdong Chen</b>, Yichong Xu, Lu Yuan, Chenguang Zhu, Jing Liao
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2023)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/abs/2211.16504">[pdf]</a>
              <a target="_blank" href="https://github.com/pleaseconnectwifi/DANCE">[code]</a>
            </div>
          </div>
        </div>

        

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/detection_hub.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'> 
            Detection Hub: Unifying Object Detection Datasets via Query Adaptation on Language Embedding
            </div>
            <div class='paper-authors'>
              Lingchen Meng, Xiyang Dai, Yinpeng Chen, Pengchuan Zhang, <b>Dongdong Chen</b>, Mengchen Liu, Jianfeng Wang, Zuxuan Wu, Lu Yuan, Yu-Gang Jiang
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2023)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/abs/2206.03484">[pdf]</a>
              <a target="_blank" href="">[code]</a>
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/meta_vp.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
             Diversity-Aware Meta Visual Prompting
            </div>
            <div class='paper-authors'>
              Qidong Huang, Xiaoyi Dong, <b>Dongdong Chen</b>, Weiming Zhang, Feifei Wang, Gang Hua, Nenghai Yu
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2023)
            </div>
            <div>
              <a target="_blank" href="">[pdf]</a>
              <a target="_blank" href="">[code]</a>
            </div>
          </div>
        </div>



        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/maskclip.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
             MaskCLIP: Masked Self-Distillation Advances Contrastive Language-Image Pretraining
            </div>
            <div class='paper-authors'>
              Xiaoyi Dong, Jianmin Bao, Yinglin Zheng, Ting Zhang, <b>Dongdong Chen</b>, Hao Yang, Ming Zeng, Weiming Zhang, Lu Yuan, Dong Chen, Fang Wen, Nenghai Yu
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2023)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/abs/2208.12262">[pdf]</a>
              <a target="_blank" href="">[code]</a>
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/peco.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              Peco: Perceptual codebook for bert pre-training of vision transformers
            </div>
            <div class='paper-authors'>
              Xiaoyi Dong, Jianmin Bao, Ting Zhang, <b>Dongdong Chen</b>, Weiming Zhang, Lu Yuan, Dong Chen, Fang Wen, Nenghai Yu
            </div>
            <div class='paper-venue'>
              Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI 2023)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/pdf/2111.12710.pdf">[pdf]</a>
              <a target="_blank" href="https://github.com/microsoft/PeCo">[code]</a>
            </div>
          </div>
        </div>
        
        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/frido.png">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              Frido: Feature Pyramid Diffusion for Complex Scene Image Synthesis
            </div>
            <div class='paper-authors'>
              Wan-Cyuan Fan, Yen-Chun Chen, <b>Dongdong Chen</b>, Yu Cheng, Lu Yuan, Yu-Chiang Frank Wang
            </div>
            <div class='paper-venue'>
              Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI 2023)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/pdf/2208.13753.pdf">[pdf]</a>
              <a target="_blank" href="https://github.com/davidhalladay/Frido">[code]</a>
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/icode.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              i-Code: An Integrative and Composable Multimodal Learning Framework
            </div>
            <div class='paper-authors'>
              Ziyi Yang, Yuwei Fang, Chenguang Zhu, Reid Pryzant, <b>Dongdong Chen</b>, et.al, Xuedong Huang
            </div>
            <div class='paper-venue'>
              Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI 2023)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/pdf/2205.01818.pdf">[pdf]</a>
              <a target="_blank">[code]</a>
            </div>
          </div>
        </div>

          <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/omnivl.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              OmniVL:One Foundation Model for Image-Language and Video-Language Tasks
            </div>
            <div class='paper-authors'>
            Junke Wang, <b>Dongdong Chen</b>, Zuxuan Wu, Chong Luo, Luowei Zhou, Yucheng Zhao, Yujia Xie, Ce Liu, Yu-Gang Jiang, Lu Yuan
            </div>
            <div class='paper-venue'>
              Thirty-sixth Conference on Neural Information Processing Systems (NeurIPs 2022)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/abs/2209.07526">[pdf]</a>
              <a target="_blank">[code]</a>
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/revive.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              REVIVE: Regional Visual Representation Matters in Knowledge-Based Visual Question Answering
            </div>
            <div class='paper-authors'>
            Yuanze Lin, Yujia Xie, <b>Dongdong Chen</b>, Yichong Xu, Chenguang Zhu, Lu Yuan
            </div>
            <div class='paper-venue'>
              Thirty-sixth Conference on Neural Information Processing Systems (NeurIPs 2022)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/abs/2206.01201">[pdf]</a>
              <a target="_blank">[code]</a>
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/bootmae.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              Bootstrapped Masked Autoencoders for Vision BERT Pretraining
            </div>
            <div class='paper-authors'>
            Xiaoyi Dong, Jianmin Bao, Ting Zhang, <b>Dongdong Chen</b>, Weiming Zhang, Lu Yuan, Dong Chen, Fang Wen, Nenghai Yu
            </div>
            <div class='paper-venue'>
              European Conference on Computer Vision (ECCV 2022)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/abs/2207.07116">[pdf]</a>
              <a target="_blank" href="https://github.com/LightDXY/BootMAE">[code]</a>
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/dpp.jpg">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              Should All Proposals be Treated Equally in Object Detection?
            </div>
            <div class='paper-authors'>
            Yunsheng Li, Yinpeng Chen, Xiyang Dai, <b>Dongdong Chen</b>, Mengchen Liu, Pei Yu, Jing Yin, Lu Yuan, Zicheng Liu, Nuno Vasconcelos
            </div>
            <div class='paper-venue'>
              European Conference on Computer Vision (ECCV 2022)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/pdf/2207.03520.pdf">[pdf]</a>
              <a target="_blank" href="https://github.com/liyunsheng13/dpp">[code]</a>
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/BEVT.png">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              BEVT: BERT Pretraining of Video Transformers
            </div>
            <div class='paper-authors'>
            Rui Wang, <b>Dongdong Chen</b>, Zuxuan Wu, Yinpeng Chen, Xiyang Dai, Mengchen Liu, Yugang Jiang, Luowei Zhou, Lu Yuan
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/abs/2112.01529">[pdf]</a>
              <a target="_blank" href="https://github.com/xyzforever/BEVT">[code]</a>
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/weakpretrain_reid.png">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              Large Scale Pre-training for Person Re-identification with Noisy Labels
            </div>
            <div class='paper-authors'>
            Dengpan Fu, <b>Dongdong Chen</b>, Hao Yang, Jianmin Bao, Lu Yuan, Lei Zhang, Houqiang Li, Dong Chen, Fang Wen
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/pdf/2203.16533.pdf">[pdf]</a>
              <a target="_blank" href="https://github.com/DengpanFu/LUPerson-NL">[code]</a>
            </div>
          </div>
        </div>
        
        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/hairclip.png">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              HairCLIP: Design Your Hair by Text and Reference Image
            </div>
            <div class='paper-authors'>
             Tianyi Wei, <b>Dongdong Chen</b>, Wenbo Zhou, Jing Liao, Zhentao Tan, Lu Yuan, Weiming Zhang, Nenghai Yu                   
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/abs/2112.05142">[pdf]</a>
              <a target="_blank" href="https://github.com/wty-ustc/HairCLIP">[code]</a>
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/clipnerf.gif">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields
            </div>
            <div class='paper-authors'>
            Can Wang, Menglei Chai, Mingming He, <b>Dongdong Chen</b>, Jing Liao                   
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/abs/2112.05139">[pdf]</a>
              <a target="_blank" href="https://github.com/cassiePython/CLIPNeRF">[code]</a>
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/FaRL.png">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              General Facial Representation Learning in a Visual-Linguistic Manner
            </div>
            <div class='paper-authors'>
            Yinglin Zheng, Hao Yang, Ting Zhang, Jianmin Bao, <b>Dongdong Chen</b>, Yangyu Huang, Lu Yuan, Dong Chen, Ming Zeng, Fang Wen
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022 Oral)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/abs/2112.03109">[pdf]</a>
              <a target="_blank" href="https://github.com/FacePerceiver/FaRL">[code]</a>
            </div>
          </div>
        </div>


        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/VQ-diffusion.png">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              Vector Quantized Diffusion Model for Text-to-Image Synthesis
            </div>
            <div class='paper-authors'>
           Shuyang Gu, Dong Chen, Jianmin Bao, Fang Wen, Bo Zhang, <b>Dongdong Chen</b>, Lu Yuan, Baining Guo                 
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022 Oral)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/abs/2111.14822">[pdf]</a>
              <a target="_blank" href="https://github.com/cientgu/VQ-Diffusion">[code]</a>
            </div>
          </div>
        </div>


       

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/mobileformer.png">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              Mobile-Former: Bridging MobileNet and Transformer
            </div>
            <div class='paper-authors'>
              Yinpeng Chen, Xiyang Dai, <b>Dongdong Chen</b>, Mengchen Liu, Xiaoyi Dong, Lu Yuan, Zicheng Liu                   
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022 Oral)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/pdf/2108.05895.pdf">[pdf]</a>
	      <a target="_blank" href="https://github.com/aaboys/mobileformer">[code]</a>
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/cswin.png">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
            CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows
            </div>
            <div class='paper-authors'>
            Xiaoyi Dong, Jianmin Bao, <b>Dongdong Chen</b>, Weiming Zhang, Nenghai Yu, Lu Yuan, Dong Chen, Baining Guo                     
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/pdf/2107.00652.pdf">[pdf]</a>
              <a target="_blank" href="https://github.com/microsoft/CSWin-Transformer">[code]</a>
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/put.png">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              Reduce Information Loss in Transformers for Pluralistic Image Inpainting
            </div>
            <div class='paper-authors'>
              Qiankun Liu, Zhentao Tan, <b>Dongdong Chen</b>, Qi Chu, Xiyang Dai, Yinpeng Chen, Mengchen Liu, Lu Yuan, Nenghai Yu                   
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/pdf/2205.05076.pdf">[pdf]</a>
              <a target="_blank" href="https://github.com/liuqk3/PUT">[code]</a>
            </div>
          </div>
        </div>

       

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/oldmovie.png">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              Bringing Old Films Back to Life
            </div>
            <div class='paper-authors'>
            Ziyu Wan, Bo Zhang, <b>Dongdong Chen</b>, Jing Liao                   
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/pdf/2203.17276.pdf">[pdf]</a>
              <a target="_blank" href="https://github.com/raywzy/Bringing-Old-Films-Back-to-Life">[code]</a>
            </div>
          </div>
        </div>
        
        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/ict_deepfake.png">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              Protecting Celebrities from DeepFake with Identity Consistency Transformer
            </div>
            <div class='paper-authors'>
            Xiaoyi Dong, Jianmin Bao, <b>Dongdong Chen</b>, Ting Zhang, Weiming Zhang, Nenghai Yu, Dong Chen, Fang Wen, Baining Guo                   
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/abs/2203.01318">[pdf]</a>
              <a target="_blank" href="https://github.com/LightDXY/ICT_DeepFake">[code]</a>
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/3d_adv.png">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              Shape-invariant 3D Adversarial Point Clouds
            </div>
            <div class='paper-authors'>
            Qidong Huang, Xiaoyi Dong, <b>Dongdong Chen</b>, Hang Zhou, Weiming Zhang, Nenghai Yu                   
            </div>
            <div class='paper-venue'>
              IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022)
            </div>
            <div>
              <a target="_blank" href="https://arxiv.org/pdf/2203.04041.pdf">[pdf]</a>
              <a target="_blank" href="https://github.com/shikiw/SI-Adv">[code]</a>
            </div>
          </div>
        </div>


        <div class='row vspace-top-small'>
            <div class='col-xs-2'>
              <img class="paper-image" src="images/nips2021_weaknas.png">
            </div>
            <div class='col-xs-10'>
              <div class='paper-title'>
              Stronger NAS with Weaker Predictors 
              </div>
              <div class='paper-authors'>
              Junru Wu, Xiyang Dai, <b>Dongdong Chen</b>, Yinpeng Chen, Mengchen Liu, Ye Yu, Zhangyang Wang, Zicheng Liu, Mei Chen, Lu Yuan                       
              </div>
              <div class='paper-venue'>
              Advances in Neural Information Processing Systems (NeurIPs 2021)
              </div>
              <div>
                <a target="_blank" href="https://openreview.net/pdf?id=NPKqZd4ZAaS">[pdf]</a>
                <a target="_blank" href="bibs/weaknas_nips2021.txt">[bibtex]</a>
                <a target="_blank" href="https://github.com/VITA-Group/WeakNAS">[code]</a>
              </div>
            </div>
          </div>

      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/inpaintingtransformer_iccv2021.png">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           High-Fidelity Pluralistic Image Completion with Transformers
          </div>
          <div class='paper-authors'>                       
          Ziyu Wan, Jingbo Zhang, <b>Dongdong Chen</b>, Jing Liao
          </div>
          <div class='paper-venue'>
           International Conference on Computer Vision (ICCV 2021)
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/pdf/2103.14031.pdf">[pdf]</a>
            <a target="_blank" href="bibs/inpainting_transformer_iccv2021.txt">[bibtex]</a>
            <a target="_blank" href="https://github.com/raywzy/ICT">[code]</a>
            <a target="_blank" href="http://raywzy.com/ICT/">[Project Page]</a>
          </div>
        </div>
      </div>

      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/noise3d_iccv2021.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           Learning with Noisy Labels for Robust Point Cloud Segmentation
          </div>
          <div class='paper-authors'>                       
          Shuquan Ye, <b>Dongdong Chen</b>, Songfang Han, Jing Liao
          </div>
          <div class='paper-venue'>
           International Conference on Computer Vision (ICCV 2021 <b>Oral</b>)
          </div>
          <div>
            <a target="_blank" href="">[pdf]</a>
            <a target="_blank" href="bibs/noise3d_iccv2021.txt">[bibtex]</a>
            <a target="_blank" href="https://github.com/pleaseconnectwifi/PNAL">[code]</a>
            <a target="_blank" href="https://shuquanye.com/PNAL_website/">[Project Page]</a>
          </div>
        </div>
      </div>

      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/micronet_iccv2021.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           Improving Image Recognition with Extremely Low FLOPs
          </div>
          <div class='paper-authors'>                       
          Yunsheng Li, Yinpeng Chen, Xiyang Dai, <b>Dongdong Chen</b>, Mengchen Liu, Lu Yuan, Zicheng Liu, Lei Zhang, Nuno Vasconcelos
          </div>
          <div class='paper-venue'>
           International Conference on Computer Vision (ICCV 2021)
          </div>
          <div>
            <a target="_blank" href="">[pdf]</a>
            <a target="_blank" href="bibs/micronet_iccv2021.txt">[bibtex]</a>
          </div>
        </div>
      </div>

      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/unsupervised_fewshot.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           Improve Unsupervised Pretraining for Few-label Transfer
          </div>
          <div class='paper-authors'>                       
          Suichan Li, <b>Dongdong Chen</b>, Yinpeng Chen, Lu Yuan, Lei Zhang, Qi Chu, Bin Liu, Nenghai Yu
          </div>
          <div class='paper-venue'>
           International Conference on Computer Vision (ICCV 2021)
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/pdf/2107.12369v1.pdf">[pdf]</a>
            <a target="_blank" href="bibs/unsup_fewshot_iccv2021.txt">[bibtex]</a>
          </div>
        </div>
      </div>

      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/unsupreid_cvpr2021.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           Unsupervised Pre-training for Person Re-identification
          </div>
          <div class='paper-authors'>                       
          Dengpan Fu, <b>Dongdong Chen</b>, Jianmin Bao, Hao Yang, Lu Yuan, Lei Zhang, Houqiang Li, Dong Chen
          </div>
          <div class='paper-venue'>
           IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2021)
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/abs/2012.03753">[pdf]</a>
            <a target="_blank" href="bibs/unsup_reid_cvpr2021.txt">[bibtex]</a>
	    <a target="_blank" href="https://github.com/DengpanFu/LUPerson">[code]</a>
          </div>
        </div>
      </div>

      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/dcd.png">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           Dynamic Convolution via Matrix Decomposition
          </div>
          <div class='paper-authors'>                       
            Yunsheng Li, Yinpeng Chen, Xiyang Dai, Mengchen Liu, <b>Dongdong Chen</b>, Ye Yu, Lu Yuan, Zicheng Liu, Mei Chen, Nuno Vasconcelos
          </div>
          <div class='paper-venue'>
           ICLR 2021
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/pdf/2103.08756.pdf">[pdf]</a>
	      <a target="_blank" href="https://github.com/liyunsheng13/dcd">[code]</a>
          </div>
        </div>
      </div>
      
      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/userclickmatting.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           Improved Image Matting via Real-time User Clicks and Uncertainty Estimation
          </div>
          <div class='paper-authors'>                       
          Tianyi Wei, <b>Dongdong Chen</b>, Wenbo Zhou, Jing Liao, Hanqing Zhao, Weiming Zhang, Nenghai Yu
          </div>
          <div class='paper-venue'>
           IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2021)
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/pdf/2012.08323.pdf">[pdf]</a>
            <a target="_blank" href="bibs/userclickmatting_cvpr2021.txt">[bibtex]</a>
          </div>
        </div>
      </div>
      
      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/dyhead_cvpr2021.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           Dynamic Head: Unifying Object Detection Heads with Attentions
          </div>
          <div class='paper-authors'>                       
          Xiyang Dai, Yinpeng Chen, Bin Xiao, <b>Dongdong Chen</b>, Mengchen Liu, Lu Yuan, Lei Zhang
          </div>
          <div class='paper-venue'>
           IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2021)
          </div>
          <div>
            <a target="_blank" href="">[pdf]</a>
            <a target="_blank" href="bibs/dyhead_cvpr2021.txt">[bibtex]</a>
	    <a target="_blank" href="https://github.com/microsoft/DynamicHead">[code]</a>
          </div>
        </div>
      </div>

      

      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/multiatt_deepfake.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           Multi-attentional Deepfake Detection
          </div>
          <div class='paper-authors'>                       
          Hanqing Zhao, Wenbo Zhou, <b>Dongdong Chen</b>, Tianyi Wei, Weiming Zhang, Nenghai Yu
          </div>
          <div class='paper-venue'>
           IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2021)
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/abs/2103.02406">[pdf]</a>
            <a target="_blank" href="bibs/deepfake_cvpr2021.txt">[bibtex]</a>
	    <a target="_blank" href="https://github.com/yoctta/multiple-attention">[code]</a>   
          </div>
        </div>
      </div>



      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/diverse_semantic_synthesis.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           Diverse Semantic Image Synthesis via Probability Distribution Modeling
          </div>
          <div class='paper-authors'>                       
          Zhentao Tan, Menglei Chai, <b>Dongdong Chen</b>, Jing Liao, Qi Chu, Bin Liu, Gang Hua, Nenghai Yu
          </div>
          <div class='paper-venue'>
           IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2021)
          </div>
          <div>
            <a target="_blank" href="https://openaccess.thecvf.com/content/CVPR2021/papers/Tan_Diverse_Semantic_Image_Synthesis_via_Probability_Distribution_Modeling_CVPR_2021_paper.pdf">[pdf]</a>
            <a target="_blank" href="">[bibtex]</a>
	    <a target="_blank" href="https://github.com/tzt101/INADE">[code]</a>
          </div>
        </div>
      </div>

      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/2020_clade.jpg">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           Efficient Semantic Image Synthesis via Class-Adaptive Normalization
          </div>
          <div class='paper-authors'>                       
          Zhentao Tan, <b>Dongdong Chen</b>, Qi Chu, Menglei Chai, Jing Liao, Mingming He, Lu Yuan, Gang Hua Nenghai Yu
          </div>
          <div class='paper-venue'>
           IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI 2021)
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/pdf/2012.04644.pdf">[pdf]</a>
            <a target="_blank" href="bibs/rethinkspade_2020.txt">[bibtex]</a>
	    <a target="_blank" href="https://github.com/tzt101/CLADE">[code]</a>
          </div>
        </div>
      </div>

      

      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/IIA.png">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
          Improving Person Re-identification with Iterative Impression Aggregation
          </div>
          <div class='paper-authors'>                       
            Dengpan Fu, Bo Xin, Jingdong Wang, <b>Dongdong Chen</b>, Jianmin Bao, Gang Hua, Houqiang Li
          </div>
          <div class='paper-venue'>
           TIP 2020
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/pdf/2009.10066.pdf">[pdf]</a>
	          <a target="_blank" href="https://github.com/DengpanFu/IIA">[code]</a>
          </div>
        </div>
      </div>

      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/greedfool_nips2020.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
          GreedyFool: Distortion-Aware Sparse Adversarial Attack
          </div>
          <div class='paper-authors'>                       
          Xiaoyi Dong, <b>Dongdong Chen</b>, Jianmin Bao, Chuan Qin, Lu Yuan, Weiming Zhang, Nenghai Yu, Dong Chen
          </div>
          <div class='paper-venue'>
           Advances in Neural Information Processing Systems (NeurIPs 2020)
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/pdf/2010.13773.pdf">[pdf]</a>
            <a target="_blank" href="bibs/greedyfool_nips2020.txt">[bibtex]</a>
	    <a target="_blank" href="https://github.com/LightDXY/GreedyFool">[code]</a>
          </div>
        </div>
      </div>

      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/passport_nips2020.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           Passport-aware Normalization for Deep Model Protection
          </div>
          <div class='paper-authors'>                       
          Jie Zhang, <b>Dongdong Chen</b>, Jing Liao, Weiming Zhang, Gang Hua, Nenghai Yu
          </div>
          <div class='paper-venue'>
           Advances in Neural Information Processing Systems (NeurIPs 2020)
          </div>
          <div>
            <a target="_blank" href="https://papers.nips.cc/paper/2020/file/ff1418e8cc993fe8abcfe3ce2003e5c5-Paper.pdf">[pdf]</a>
            <a target="_blank" href="bibs/passport_nips2020.txt">[bibtex]</a>
            <a target="_blank" href="https://github.com/ZJZAC/Passport-aware-Normalization">[code]</a>
          </div>
        </div>
      </div>

      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/dyrelu.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           Dynamic ReLU
          </div>
          <div class='paper-authors'>                       
          Yinpeng Chen, Xiyang Dai, Mengchen Liu, <b>Dongdong Chen</b>, Lu Yuan, Zicheng Liu
          </div>
          <div class='paper-venue'>
           European Conference on Computer Vision (ECCV 2020)
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/pdf/2003.10027.pdf">[pdf]</a>
            <a target="_blank" href="bibs/dyrelu_eccv2020.txt">[bibtex]</a>
          </div>
        </div>
      </div>

      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/da-nas.png">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
          DA-NAS: Data Adapted Pruning for Efficient Neural Architecture Search
          </div>
          <div class='paper-authors'>                       
          Xiyang Dai, <b>Dongdong Chen</b>, Mengchen Liu, Yinpeng Chen, Lu Yuan
          </div>
          <div class='paper-venue'>
           European Conference on Computer Vision (ECCV 2020)
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/pdf/2003.12563.pdf">[pdf]</a>
            <a target="_blank" href="bibs/danas_eccv2020.txt">[bibtex]</a>
          </div>
        </div>
      </div>

     <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/sig20_michigan.gif">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           MichiGAN: Multi-Input-Conditioned Hair Image Generation for Portrait Editing
          </div>
          <div class='paper-authors'>                       
          Zhentao Tan, Menglei Chai, <b>Dongdong Chen</b>, Jing Liao, Qi Chu, Lu Yuan, Sergey Tulyakov, Nenghai Yu
          </div>
          <div class='paper-venue'>
           ACM Transactions on Graphics (SIGGRAPH) 2020
          </div>
          <div>
            <a target="_blank" href="https://mlchai.com/files/tan2020michigan.pdf">[pdf]</a>
            <a target="_blank" href="https://github.com/tzt101/MichiGAN">[code]</a>
            <a target="_blank" href="bibs/michigan_sig2020.txt">[bibtex]</a>
          </div>
        </div>
      </div>


        <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/cvpr20_dyconv.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           Dynamic Convolution: Attention over Convolution Kernels
          </div>
          <div class='paper-authors'>                       
          Yinpeng Chen, Xiyang Dai, Mengchen Liu, <b>Dongdong Chen</b>, Lu Yuan, Zicheng Liu
          </div>
          <div class='paper-venue'>
           IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2020)
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/pdf/1912.03458.pdf">[pdf]</a>
            <a target="_blank" href="bibs/dyconv_cvpr2020.txt">[bibtex]</a>
          </div>
        </div>
      </div>


        <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/cvpr20_bringold.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           Bringing Old Photos Back to Life
          </div>
          <div class='paper-authors'>                       
          Ziyu Wan, Bo Zhang, <b>Dongdong Chen</b>, Pan Zhang, Dong Chen, Jing Liao, Fan Wen
          </div>
          <div class='paper-venue'>
           IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2020 <b>Oral</b>)
          </div>
          <div>		  
            <a target="_blank" href="https://arxiv.org/pdf/2004.09484.pdf">[pdf]</a>
	    <a target="_blank" href="https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life/">[code]</a>
            <a target="_blank" href="bibs/oldphoto_cvpr2020.txt">[bibtex]</a>
            <a target="_blank" href="https://arxiv.org/abs/2009.07047">[PAMI extension]</a>
          </div>
        </div>
      </div>


        <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/cvpr20_semi_density.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           Density-Aware Graph for Deep Semi-Supervised Visual Recognition
          </div>
          <div class='paper-authors'>                       
          Suichan Li, Bin Liu, <b>Dongdong Chen</b>, Qi Chu, Lu Yuan, Nenghai Yu
          </div>
          <div class='paper-venue'>
           IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2020)
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/pdf/2003.13194.pdf">[pdf]</a>
            <a target="_blank" href="bibs/density_semi_cvpr2020.txt">[bibtex]</a>
          </div>
        </div>
      </div>


        <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/cvpr20_superatt.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           Robust Superpixel-Guided Attentional Adversarial Attack
          </div>
          <div class='paper-authors'>             
            Xiaoyi Dong, Jiangfan Han, <b>Dongdong Chen</b>, et al., Nenghai Yu
          </div>
          <div class='paper-venue'>
           IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2020)
          </div>
          <div>
            <a target="_blank" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Dong_Robust_Superpixel-Guided_Attentional_Adversarial_Attack_CVPR_2020_paper.pdf">[pdf]</a>
            <a target="_blank" href="bibs/superpixel_adv_cvpr2020.txt">[bibtex]</a>
          </div>
        </div>
      </div>


        <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/cvpr20_sr3d.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           Self-Robust 3D Point Recognition via Gather-vector Guidance
          </div>
          <div class='paper-authors'>             
            Xiaoyi Dong, <b>Dongdong Chen</b>, et al., Nenghai Yu
          </div>
          <div class='paper-venue'>
           IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2020)
          </div>
          <div>
            <a target="_blank" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Dong_Self-Robust_3D_Point_Recognition_via_Gather-Vector_Guidance_CVPR_2020_paper.pdf">[pdf]</a>
            <a target="_blank" href="bibs/reboust_3drec_cvpr2020.txt">[bibtex]</a>
          </div>
        </div>
      </div>


      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/cvpr20_lggan.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
           LG-GAN: Label Guided Adversarial Network for Flexible Targeted Attack of Point Cloud-based Deep Networks
          </div>
          <div class='paper-authors'>             
            Hang Zhou, <b>Dongdong Chen</b>, et al., Nenghai Yu
          </div>
          <div class='paper-venue'>
           IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2020)
          </div>
          <div>
            <a target="_blank" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhou_LG-GAN_Label_Guided_Adversarial_Network_for_Flexible_Targeted_Attack_of_CVPR_2020_paper.pdf">[pdf]</a>
            <a target="_blank" href="bibs/LGGAN_cvpr2020.txt">[bibtex]</a>
          </div>
        </div>
      </div>

      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/aaai2020_watermark.PNG">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
            Model Watermarking for Image Processing Networks
          </div>
          <div class='paper-authors'>
            Jie Zhang*, <b>Dongdong Chen</b>, et al., Nenghai Yu 
          </div>
          <div class='paper-venue'>
            Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI 2020)
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/pdf/2002.11088.pdf">[pdf]</a>
            <a target="_blank" href="bibs/modelwatermark_AAAI2020.txt">[bibtex]</a>
            <a target="_blank" href="https://arxiv.org/pdf/2103.04980.pdf">[TPAMI Version]</a>  
          </div>
        </div>
      </div>


        <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/zero_nip2019_nail.png">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
            Transductive Zero-Shot Learning with Visual Structure Constraint
          </div>
          <div class='paper-authors'>
            Ziyu Wan*, <b>Dongdong Chen*</b>, Yan Li, Xingguang Yan, Junge Zhang, Yizhou Yu, Jing Liao (*Equal Contribution)
          </div>
          <div class='paper-venue'>
            Thirty-third Conference on Neural Information Processing Systems (NeurIPS 2019)
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/abs/1901.01570.pdf">[pdf]</a>
            <a target="_blank" href="bibs/zeroshot_nips2019.txt">[bibtex]</a>
            <a target="_blank" href="https://link.springer.com/article/10.1007/s11263-021-01451-1">[IJCV Extension]</a>
          </div>
        </div>
      </div>

      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/attack_iccv2019_nail.png">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
            Once a MAN: Towards Multi-Target Attack via Learning Multi-Target Adversarial Network Once 
          </div>
          <div class='paper-authors'>
            Jiangfan Han, Xiaoyi Dong, Ruimao Zhang, <b>Dongdong Chen</b>, Weiming Zhang, Nenghai Yu, Ping Luo, Xiaogang Wang
          </div>
          <div class='paper-venue'>
            Proceedings of the IEEE International Conference on Computer Vision (ICCV 2019)
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/abs/1908.05185.pdf">[pdf]</a>
            <a target="_blank" href="bibs/attack_iccv2019.txt">[bibtex]</a>
          </div>
        </div>
      </div>
      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/decouple_pami19_nail.png">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
            A General Decoupled Learning Framework for Parameterized Image Operators
          </div>
          <div class='paper-authors'>
            Qingnan Fan*, <b>Dongdong Chen*</b>, Lu Yuan, Gang Hua, Nenghai Yu, Baoquan Chen (*Equal Contribution)
          </div>
          <div class='paper-venue'>
            IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI 2019)
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/abs/1907.05852.pdf">[pdf]</a>
            <a target="_blank" href="bibs/decouple_pami2019.txt">[bibtex]</a>
          </div>
        </div>
      </div>
        <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/tog18_neural_nail.png">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
            Progressive Color Transfer with Dense Semantic Correspondences
          </div>
          <div class='paper-authors'>
            Mingming He, Jing Liao, <b>Dongdong Chen*</b>, Lu Yuan, Pedro V Sander
          </div>
          <div class='paper-venue'>
            ACM TOG 2018
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/pdf/1710.00756.pdf">[pdf]</a>
            <a target="_blank" href="bibs/neural_tog2018.txt">[bibtex]</a>
          </div>
        </div>
      </div>

      <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/mirror_reflection.png">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
            Mirror, Mirror, on the Wall, Who's Got the Clearest Image of Them All?-A Tailored Approach to Single Image Reflection Removal
          </div>
          <div class='paper-authors'>                       
            Daniel Heydecker, Georg Maierhofer, Angelica I Aviles-Rivero, Qingnan Fan, <b>Dongdong Chen</b>, Carola-Bibiane Schnlieb, Sabine Ssstrunk
          </div>
          <div class='paper-venue'>
           TIP 2019
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/pdf/1805.11589.pdf">[pdf]</a>
          </div>
        </div>
      </div>

        <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/wacv19_nail.png">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
            Gated Context Aggregation Network for Image Dehazing and Deraining
          </div>
          <div class='paper-authors'>
           <b>Dongdong Chen*</b>, Mingming He, Qingnan Fan, Jing Liao, Liheng Zhang, Dongdong Hou, Lu Yuan, Gang Hua
          </div>
          <div class='paper-venue'>
            WACV 2019
          </div>
          <div>
            <a target="_blank" href="https://arxiv.org/pdf/1811.08747.pdf">[pdf]</a>
            <a target="_blank" href="https://github.com/cddlyf/GCANet">[code]</a>
            <a target="_blank" href="bibs/gcanet_wacv2019.txt">[bibtex]</a>
          </div>
        </div>
      </div>

        <div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/eccv18_nail.png">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
            Decouple Learning for Parameterized Image Operators
          </div>
          <div class='paper-authors'>
           Qingnan Fan*, <b>Dongdong Chen*</b>, Lu Yuan, Gang Hua, Nenghai Yu, Baoquan Chen (* Equal Contribution)
          </div>
          <div class='paper-venue'>
            ECCV 2018
          </div>
          <div>
            <a target="_blank" href="pubs/decouple_eccv2018.pdf">[pdf]</a>
            <a target="_blank" href="https://github.com/fqnchina/DecoupleLearning">[code]</a>
            <a target="_blank" href="bibs/decouple_eccv2018.txt">[bibtex]</a>
          </div>
        </div>
      </div>

		<div class='row vspace-top-small'>
        <div class='col-xs-2'>
          <img class="paper-image" src="images/sig18_nail.png">
        </div>
        <div class='col-xs-10'>
          <div class='paper-title'>
            Deep Exemplar-based Colorization
          </div>
          <div class='paper-authors'>
            Mingming He*, <b>Dongdong Chen*</b>, Jing Liao, Pedro V.Sander, Lu Yuan (* Equal Contribution)
          </div>
          <div class='paper-venue'>
            Siggraph 2018
          </div>
          <div>
            <a target="_blank" href="pubs/colorization_sig18.pdf">[pdf]</a>
            <a target="_blank" href='https://github.com/msracver/Deep-Exemplar-based-Colorization'>[code]</a>
            <a target="_blank" href='supp/deep_exam_colorization/index.html'>[supplementary]</a>
            <a target="_blank" href="bibs/deepexamplar_sig2018.txt">[bibtex]</a>
          </div>
        </div>
      </div>

		<div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/stereo_style_nail.gif">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              Stereoscopic Neural Style Transfer
            </div>
            <div class='paper-authors'>
              <b>Dongdong Chen</b>, Lu Yuan, Jing Liao, Nenghai Yu, Gang Hua
            </div>
            <div class='paper-venue'>
              CVPR 2018
            </div>
            <div>
              <a target="_blank" href="pubs/stereostyle_cvpr2018.pdf">[pdf]</a>
              <a target="_blank" href="pubs/stereo_supp.pdf">[supplementary]</a>
              <a target="_blank" href="https://www.youtube.com/watch?v=7py0Nq8TxYs">[video]</a>
              <a target="_blank" href="bibs/stereo_cvpr2018.txt">[bibtex]</a>
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/covst_nail.gif">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              Coherent Online Video Style Transfer
            </div>
            <div class='paper-authors'>
              <b>Dongdong Chen</b>, Jing Liao, Lu Yuan, Nenghai Yu, Gang Hua
            </div>
            <div class='paper-venue'>
              ICCV 2017
            </div>
            <div>
              <a target="_blank" href="pubs/coherent_video_st.pdf">[pdf]</a>
              <a target="_blank" href="https://www.youtube.com/watch?v=vMyMUNvsGfQ">[video]</a>
              <a target="_blank" href="bibs/cvst_iccv2017.txt">[bibtex]</a>
            </div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/stylebank_nail.gif">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              StyleBank: An Explicit Representation for Neural Image Style Transfer
            </div>
            <div class='paper-authors'>
              <b>Dongdong Chen</b>, Lu Yuan, Jing Liao, Nenghai Yu, Gang Hua
            </div>
            <div class='paper-venue'>
              CVPR 2017
            </div>
            <div>
              <a target="_blank" href="pubs/stylebank_cvpr2017.pdf">[pdf]</a>
              <a target="_blank" href="pubs/sbk_supp.pdf">[supplementary]</a>
              <a target="_blank" href="https://www.youtube.com/watch?v=RA0NHlsLT4A">[video]</a>
              <a target="_blank" href="bibs/stylebank_cvpr2017.txt">[bibtex]</a>
              <a target="_blank" href="pubs/stylebank_pami.pdf">[TPAMI Version]</a>  
            </div>
			<div>
			  <a target="_blank" href="http://www.msra.cn/zh-cn/news/blogs/2017/06/microsoft-pix-20170616.aspx"><font color="red">Congrats! Our technique is adopted by Microsoft Pix.</font><a>
			</div>
          </div>
        </div>

        <div class='row vspace-top-small'>
          <div class='col-xs-2'>
            <img class="paper-image" src="images/3d_mov.png">
          </div>
          <div class='col-xs-10'>
            <div class='paper-title'>
              Automatic Extraction of Moving Objects from Image and LIDAR Sequences
            </div>
            <div class='paper-authors'>
              Jizhou Yan, <b>Dongdong Chen</b>, Heesoo Myeong, Takaaki Shiratori, Yi Ma
            </div>
            <div class='paper-venue'>
              International Conference on 3D Vision 2014
            </div>
            <div>
              <a href="pubs/3dv_2014.pdf">[pdf]</a></a>
              <a target="_blank" href="bibs/3dv_2014.txt">[bibtex]</a>
            </div> 

          </div>
        </div>
        <div class='row'>
          <h1>Book Chapters</h1>
        </div>

        <div class='row vspace-top-small'>
          <div>
            <i>Gang Hua, Dongdong Chen</i>, <b>"Deep Conditional Image Generation: Towards Controllable Visual Pattern Modeling"</b>, in Advanced Methods and Deep Learning in Computer Vision, editted by E .R. Davies and Matthew Turk, Elsevier, 2021.
          </div>
          <div>
            <i>Dongdong Chen, Lu Yuan, Gang Hua,</i> <b>"Deep Style Transfer"</b>, in Computer Vision: A Reference Guide, Second Edition, edited by Katsushi Ikeuchi, Springer 2020
          </div>
          <div>
            <i>Dongdong Chen, Lu Yuan, Gang Hua,</i> <b>"Texutre Synthesis"</b>, in Computer Vision: A Reference Guide, Second Edition, edited by Katsushi Ikeuchi, Springer 2020
          </div>
           
        </div>

        <div class='row'>
          <hr>
        </div>

        <div class='row'>
          <hr>
        </div>

        <div class='row'>
          <h1>Experience</h1>
        </div>

        <div class='row vspace-top-small'>
          <div>
            <b>2010.08~2014.06: </b> &nbsp;&nbsp;Bachelor in Electrical Engineering in University of Science and Technology of China
          </div>
          <div>
            <b>2013.07~2014.05: </b> &nbsp;&nbsp;Intern in MSRA advised by Yi Ma and Jian Sun respectively
          </div>
          <div>
            <b>2015.07~2015.10: </b> &nbsp;&nbsp;Intern in Alibaba Group Beijing
          </div>
          <div>
            <b>2015.11~2018.03: </b> &thinsp;&nbsp;Intern in MSRA advised by Jian Sun and Gang Hua and Lu Yuan respectively.
          </div>
          <div>
            <b>2018.04~2018.09: </b> &thinsp;&nbsp;Intern in Microsoft Redmond advised Gang Hua.
          </div>
        </div>

        <div class='row'>
          <hr>
        </div>
		
		<div class='row'>
          <h1>Professional Activities</h1>
        </div>
    
    <div class='row vspace-top-small'>
    <div>
       Invited as Area Chair of NeurIPs 2023
   </div>
   <div>
       Invited as Area Chair of CVPR 2023
   </div>
   <div>
    Invited as Area Chair of ECCV 2022
    </div>
    <div>
        Invited as Associate Editor with Pattern Recognition from 2022
	    </div>
    <div>
    Invited as Area Chair of ICPR 2022
    </div>
    <div>
    Invited as Senior Program Committee (SPC) of AAAI 2022 and Area Chair of CVPR 2022
    </div>
    <div>
    Reviewer: CVPR 2021, ICCV 2021,  NeurIPs 2021
    </div>
    <div>
      Reviewer: CVPR 2020, ECCV 2020,	NeurIPs 2020,  AAAI 2020,
    </div>
    <div>
      Reviewer: CVPR 2019, ICCV 2019, AAAI 2019, PRCV 2019, ICME 2019, ICIG 2019    
    </div>
	  <div>
      Reviewer: CVPR2018, ECCV 2018, ACCV2018	 
    </div>
    <div>
      Reviewer: IEEE Transactions on Pattern Analysis and Machine Intelligence(TPAMI)
    </div>
    <div>
      Reviewer: International Journal of Comuter Vision(IJCV)
    </div>
    <div>
      Reviewer: IEEE Transactions on Image Processing(TIP)		  
    </div>    
	  <div>
	  Reviewer: IEEE Transactions on MultiMedia(TMM)
	  </div>
	   <div>
	  Reviewer: IEEE Transactions on Circuits and Systems for Video Technology(TCSVT)
	  </div>
	   <div>
	  Reviewer:  Machine Vision and Applications(MVAP)	   
	   </div>
	  <div>
	  Reviewer: Journal of Selected Topics in Signal Processing (JSTSP)
	  </div>
		 <div>
    Reviewer:  Public Library of Science (PLOS ONE)
     </div>
		 
        <div class='row'>
          <h1>Awards and Honors</h1>
        </div>
        <div class='row vspace-top-small'>
	  <div>
	   Outstanding Reviewer Award of CVPR 2020, CVPR 2021, ICCV 2021	  
	  </div>
          <div>
          Chinese Academy of Sciences President Award (Special), July 2019       
          </div>
          <div>
          National Scholarship for Graduate Students, Nov 2018       
          </div>
          <div>
          (3/2950 Teams) FashionAI Global ChallengeAttributes Recognition of Apparel 2018        
          </div>
          <div>
          (7/2322 Teams) FashionAI Global ChallengeKey Points Detection of Apparel 2018
          </div>
          <div>
          National ScholarShip, Nov 2012
          </div>
          <div>
          National ScholarShip, Nov 2013
          </div>
          <div>
          Grand Prize (1/1438 teams) in CCF National Youth Innovation Contest of Big Data 2015
          </div>
          <div>
          Top 5 in Tianyi Algorithm Contest of Big Data 2016
          </div>
          <div>
          Best Demo Prize of Di-Tech Algorithm Contest of Big Data 2016
          </div>
        </div>
      </div>
    </div>
	</body>
</html>
